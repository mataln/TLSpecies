{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration notebook for TreeLS\n",
    "This notebook will outline the tree species classification process, from raw point clouds of individual trees through predicting with a trained model. <br/>\n",
    "\n",
    "For this notebook, the following file/folder structure is used: <br/>\n",
    "\n",
    "<pre>\n",
    "|-- LICENSE \n",
    "|-- README.md \n",
    "|-- TreeLS.yml \n",
    "| \n",
    "|-- data \n",
    "|   |-- treesXYZ \n",
    "|       |-- tree_id1.txt --> .txt files with containing point cloud data \n",
    "|                             i.e x1 y1 z1\n",
    "|                                 x2 y2 z2\n",
    "|       |-- tree_id2.txt      \n",
    "|       |-- ... \n",
    "|\n",
    "|   |-- meta\n",
    "|       |-- tree-meta.csv --> metadata file describing species for each sample in treesXYZ\n",
    "|                             it should have two columns 'id' and 'sp' containing identifiers and species labels\n",
    "|                             with the id matching the filename for the corresponding pointcloud (w/o file extension)\n",
    "|\n",
    "|                             e.g. \n",
    "|                             id\t    sp\n",
    "|                             tree_id1\tQUEFAG\n",
    "|                             ...\n",
    "| \n",
    "|-- utils \n",
    "|   |-- __init__.py \n",
    "|   |-- dataset.py \n",
    "|   |-- utils.py \n",
    "|   |-- train.py \n",
    "|   |-- test.py \n",
    "| \n",
    "|-- sh \n",
    "|   |-- dl-simpleview.sh \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running anything, the code for the core model needs to be pulled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clone Simpleview repo\n",
    "!git clone https://github.com/IsaacCorley/simpleview-pytorch\n",
    "\n",
    "!cd simpleview-pytorch\n",
    "\n",
    "#Remove git stuff + non-classification bits\n",
    "!rm -r assets\n",
    "!rm -f LICENSE\n",
    "!rm -f README.md\n",
    "!rm -f .gitignore\n",
    "\n",
    "!cd ..\n",
    "\n",
    "!mv simpleview-pytorch/simpleview_pytorch simpleview_pytorch\n",
    "!rm -r -f simpleview-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/miniconda3/envs/treels/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import shutil, os\n",
    "import numpy as np\n",
    "import utils\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by taking a look at some of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = utils.pc_from_txt('data/treesXYZ/alt01_2.txt') #Load from file\n",
    "cloud = utils.center_and_scale(cloud) #Center and scale into [-1,1]^3\n",
    "\n",
    "sample_images = utils.get_depth_images_from_cloud(cloud, image_dim=256) #Generate the projections\n",
    "fig, ax = utils.plot_depth_images(sample_images, nrows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data isn't split into train/validation/test sets, so we'll do it randomly here. Since the dataset we used in the paper was quite large, the class balance turns out about the same without the need for stratified sampling. If you want to use specific samples in the train/test sets, it's fine to separate the folders by hand - just skip the two cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir('data/treesXYZ/')\n",
    "seed = 0\n",
    "train_filenames, rest_filenames = train_test_split(filenames, train_size=0.7, shuffle=True, random_state=seed) #0.7/0.3 for train data/rest of data\n",
    "val_filenames, test_filenames = train_test_split(rest_filenames, train_size=0.5, shuffle=True, random_state=seed) #Split rest of data 0.5/0.5 for 0.15/0.15 val/test overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll copy the train/test/val splits into separate folders. You could delete the orginial folder to save space. This cell can take a while, depending on how much data there is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train folder\n",
    "train_folder = 'data/train'\n",
    "os.mkdir(train_folder)\n",
    "for f in train_filenames: \n",
    "    shutil.copy(f'data/treesXYZ/{f}', train_folder)\n",
    "\n",
    "#Val folder\n",
    "val_folder = 'data/val'\n",
    "os.mkdir(val_folder)\n",
    "for f in val_filenames: \n",
    "    shutil.copy(f'data/treesXYZ/{f}', val_folder)\n",
    "\n",
    "#Test folder\n",
    "test_folder = 'data/test'\n",
    "os.mkdir(test_folder)\n",
    "for f in test_filenames: \n",
    "    shutil.copy(f'data/treesXYZ/{f}', test_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch datasets can now be built from these folders, along with the original metadata file. This does mean that the data gets duplicated quite a lot of times. Please remove any copies that you don't need; they are left in place here to aid script debugging. \n",
    "\n",
    "The random transforms to be used (Rotation, Translation, Scaling) should be set per-dataset. They are OFF by default, and will also be forced off for the validation/test sets during inference. All three are enabled for the train set in the cell below. Various other parameters (Augmentation hyperparameters, camera parameters) can also be adjusted similarly. They are equal to the values described in the paper by default.\n",
    "\n",
    "If you don't want any transforms, you should set the value of .transforms to ['none'] (i.e. in a list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import transforms\n",
    "\n",
    "\n",
    "metadata_file = 'data/meta/tree-meta.csv'\n",
    "\n",
    "train_dataset = utils.TreeSpeciesPointDataset(data_dir='data/train/', metadata_file=metadata_file)\n",
    "train_dataset.set_params(transforms = ['rotation','translation','scaling']) #Other parameters can be changes - for example ...set_params(image_dim=128) .set_params(max_rotation=0.5) etc.\n",
    "torch.save(train_dataset, \"data/trees_train.pt\")\n",
    "\n",
    "val_dataset = utils.TreeSpeciesPointDataset(data_dir='data/val/', metadata_file=metadata_file)\n",
    "torch.save(val_dataset, \"data/trees_val.pt\")\n",
    "\n",
    "test_dataset = utils.TreeSpeciesPointDataset(data_dir='data/test/', metadata_file=metadata_file)\n",
    "torch.save(test_dataset, \"data/trees_test.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some quick sanity checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_depth_images(test_dataset.__getitem__(54)['depth_images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.meta_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First there are a few training parameters to specify - note that you should specify the species in your dataset you wish to include here. For example, 5 species are considered from our dataset. A single juniper tree and unidentified species are not included.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"batch_size\":128,\n",
    "    \"shuffle_dataset\":True,\n",
    "    \"random_seed\":0,\n",
    "    \"learning_rate\":[0.001,50,0.5],  #[init, step_size, gamma] for scheduler\n",
    "    \"momentum\":0.9, #Only used for sgd, ignroed for adam\n",
    "    \"epochs\":10,\n",
    "    \"loss_fn\":\"smooth-loss\",\n",
    "    \"optimizer\":\"adam\",\n",
    "    \"train_sampler\":\"balanced\",\n",
    "\n",
    "    \"model\":\"SimpleView\",\n",
    "\n",
    "    \"species\":[\"QUEFAG\", \"PINNIG\", \"QUEILE\", \"PINSYL\", \"PINPIN\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a model using the train/val/test datasets. If you try to rerun this cell without restarting the kernel, it might crash. If you use VS Code, it might hide some of the output.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.train(train_data=\"data/trees_train.pt\",\n",
    "            val_data=\"data/trees_val.pt\",\n",
    "            test_data=\"data/trees_test.pt\",\n",
    "            model_dir='models',\n",
    "            params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the model predictions on the test dataset, and plot the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'num_views'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/matt/work/TreeLS/demo.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/matt/work/TreeLS/demo.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m _, labels, predictions, species \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mpredict_from_dirs(\u001b[39m'\u001b[39;49m\u001b[39mdata/trees_test.pt\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmodels/2022-08-15 11:30:23.374472_best\u001b[39;49m\u001b[39m'\u001b[39;49m, params\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mspecies\u001b[39;49m\u001b[39m'\u001b[39;49m:[\u001b[39m\"\u001b[39;49m\u001b[39mQUEFAG\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mPINNIG\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mQUEILE\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mPINSYL\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mPINPIN\u001b[39;49m\u001b[39m\"\u001b[39;49m]}) \u001b[39m#Predictions for whole test dataset\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/matt/work/TreeLS/demo.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(species) \u001b[39m#Might be in a different order to the one specified in the config\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/matt/work/TreeLS/demo.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m24\u001b[39m,\u001b[39m24\u001b[39m))\n",
      "File \u001b[0;32m~/work/TreeLS/utils/test.py:75\u001b[0m, in \u001b[0;36mpredict_from_dirs\u001b[0;34m(dataset_dir, model_dir, params)\u001b[0m\n\u001b[1;32m     71\u001b[0m dataset \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(dataset_dir)\n\u001b[1;32m     73\u001b[0m \u001b[39m#Load model\u001b[39;00m\n\u001b[1;32m     74\u001b[0m model \u001b[39m=\u001b[39m SimpleView(\n\u001b[0;32m---> 75\u001b[0m         num_views\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39;49m\u001b[39mnum_views\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     76\u001b[0m         num_classes\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(params[\u001b[39m\"\u001b[39m\u001b[39mspecies\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     79\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(model_dir))\n\u001b[1;32m     81\u001b[0m \u001b[39m#Load validation indices\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'num_views'"
     ]
    }
   ],
   "source": [
    "_, labels, predictions, species = utils.predict_from_dirs('data/trees_test.pt', 'models/2022-08-15 11:30:23.374472_best', params={'species':[\"QUEFAG\", \"PINNIG\", \"QUEILE\", \"PINSYL\", \"PINPIN\"], 'num_views':6}) #Predictions for whole test dataset\n",
    "print(species) #Might be in a different order to the one specified in the config\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(24,24))\n",
    "tickFont = 28\n",
    "axFont = 48\n",
    "annotFont = 36\n",
    "\n",
    "cm = confusion_matrix(labels.cpu(), predictions.cpu(), normalize='true')\n",
    "hm = sns.heatmap(cm, annot=True, ax=ax[0], cbar=False, annot_kws={\"fontsize\":annotFont})\n",
    "hm.set_xticklabels(species, fontsize=tickFont, style = 'italic')\n",
    "ax[0].set_yticklabels(species, fontsize=tickFont)\n",
    "hm.set_ylabel('True Labels', fontsize=axFont+2)\n",
    "hm.set_xlabel('Predictions', fontsize=axFont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('treels')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11a21a69754829048d4a76e7a98175df30293a16bef763aec20f201f35b25175"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
